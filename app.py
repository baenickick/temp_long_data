# app.py
import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from datetime import datetime
import io

st.set_page_config(page_title="ìƒí™œì¸êµ¬ ë°ì´í„° ë³‘í•©", layout="wide")
st.title("ìƒí™œì¸êµ¬ CSV ë³‘í•© ì›¹ì•± (ì™¸êµ­ì¸/êµ­ë‚´ì¸êµ¬ ìë™ êµ¬ë¶„)")

def detect_delimiter(sample_bytes):
    s = sample_bytes[:2048].decode('utf-8', errors='ignore')
    return '\t' if s.count('\t') > s.count(',') else ','

def process_foreigner_file(content_bytes, filename):
    """ì™¸êµ­ì¸ íŒŒì¼ ì²˜ë¦¬"""
    delim = detect_delimiter(content_bytes)
    df = None
    for enc in ('utf-8', 'cp949', 'utf-8-sig'):
        try:
            df = pd.read_csv(io.BytesIO(content_bytes), encoding=enc, delimiter=delim, low_memory=False, dtype=str)
            break
        except Exception:
            continue
    if df is None:
        raise ValueError(f"{filename}: ì¸ì½”ë”© ì‹¤íŒ¨")
    
    df.columns = df.columns.str.strip().str.replace('"','').str.replace('?','')
    required = ['ê¸°ì¤€ì¼ID','ì‹œê°„ëŒ€êµ¬ë¶„','ì§‘ê³„êµ¬ì½”ë“œ','ì´ìƒí™œì¸êµ¬ìˆ˜','ì¤‘êµ­ì¸ì²´ë¥˜ì¸êµ¬ìˆ˜','ì¤‘êµ­ì™¸ì™¸êµ­ì¸ì²´ë¥˜ì¸êµ¬ìˆ˜']
    if not all(c in df.columns for c in required):
        raise ValueError(f"{filename}: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½")
    
    df = df[required].copy()
    target_codes = ['1104065', '1104066', '1104067', '1104068']
    df['ì§‘ê³„êµ¬ì½”ë“œ_str'] = df['ì§‘ê³„êµ¬ì½”ë“œ'].astype(str)
    filter_mask = df['ì§‘ê³„êµ¬ì½”ë“œ_str'].str[:7].isin(target_codes)
    df = df[filter_mask].copy()
    
    if len(df) == 0:
        return pd.DataFrame()
    
    df['DATE'] = pd.to_datetime(df['ê¸°ì¤€ì¼ID'].astype(str), format='%Y%m%d', errors='coerce')
    df['TIME'] = pd.to_numeric(df['ì‹œê°„ëŒ€êµ¬ë¶„'], errors='coerce')
    wmap = {0:'ì›”ìš”ì¼',1:'í™”ìš”ì¼',2:'ìˆ˜ìš”ì¼',3:'ëª©ìš”ì¼',4:'ê¸ˆìš”ì¼',5:'í† ìš”ì¼',6:'ì¼ìš”ì¼'}
    df['ìš”ì¼'] = df['DATE'].dt.dayofweek.map(wmap)
    df['ì£¼ì¤‘_or_ì£¼ë§'] = np.where(df['DATE'].dt.dayofweek >= 5, 'ì£¼ë§', 'ì£¼ì¤‘')
    df['CODE'] = df['ì§‘ê³„êµ¬ì½”ë“œ_str']
    
    return pd.DataFrame({
        'DATE': df['DATE'].dt.strftime('%Y-%m-%d'),
        'ìš”ì¼': df['ìš”ì¼'],
        'ì£¼ì¤‘_or_ì£¼ë§': df['ì£¼ì¤‘_or_ì£¼ë§'],
        'TIME': df['TIME'],
        'CODE': df['CODE'],
        'ALL': pd.to_numeric(df['ì´ìƒí™œì¸êµ¬ìˆ˜'], errors='coerce'),
        'CHN': pd.to_numeric(df['ì¤‘êµ­ì¸ì²´ë¥˜ì¸êµ¬ìˆ˜'], errors='coerce'),
        'EXP_CHN': pd.to_numeric(df['ì¤‘êµ­ì™¸ì™¸êµ­ì¸ì²´ë¥˜ì¸êµ¬ìˆ˜'], errors='coerce')
    }).dropna(subset=['DATE','TIME','CODE'])

def process_local_file(content_bytes, filename):
    """êµ­ë‚´ì¸êµ¬ íŒŒì¼ ì²˜ë¦¬"""
    delim = detect_delimiter(content_bytes)
    df = None
    for enc in ('utf-8', 'cp949', 'utf-8-sig'):
        try:
            df = pd.read_csv(io.BytesIO(content_bytes), encoding=enc, delimiter=delim, low_memory=False, dtype=str)
            break
        except Exception:
            continue
    if df is None:
        raise ValueError(f"{filename}: ì¸ì½”ë”© ì‹¤íŒ¨")
    
    df.columns = df.columns.str.strip().str.replace('"','').str.replace('?','')
    
    basic_cols = ['ê¸°ì¤€ì¼ID','ì‹œê°„ëŒ€êµ¬ë¶„','í–‰ì •ë™ì½”ë“œ','ì§‘ê³„êµ¬ì½”ë“œ','ì´ìƒí™œì¸êµ¬ìˆ˜']
    male_cols = [
        'ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜',
        'ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜',
        'ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜',
        'ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜',
        'ë‚¨ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜','ë‚¨ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜'
    ]
    female_cols = [
        'ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜',
        'ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜',
        'ì—¬ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜',
        'ì—¬ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜',
        'ì—¬ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜','ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜'
    ]
    
    required = basic_cols + male_cols + female_cols
    if not all(c in df.columns for c in required):
        raise ValueError(f"{filename}: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½")
    
    df = df[required].copy()
    target_codes = ['1104065', '1104066', '1104067', '1104068']
    df['ì§‘ê³„êµ¬ì½”ë“œ_str'] = df['ì§‘ê³„êµ¬ì½”ë“œ'].astype(str)
    filter_mask = df['ì§‘ê³„êµ¬ì½”ë“œ_str'].str[:7].isin(target_codes)
    df = df[filter_mask].copy()
    
    if len(df) == 0:
        return pd.DataFrame()
    
    df['DATE'] = pd.to_datetime(df['ê¸°ì¤€ì¼ID'].astype(str), format='%Y%m%d', errors='coerce')
    df['TIME'] = pd.to_numeric(df['ì‹œê°„ëŒ€êµ¬ë¶„'], errors='coerce')
    wmap = {0:'ì›”ìš”ì¼',1:'í™”ìš”ì¼',2:'ìˆ˜ìš”ì¼',3:'ëª©ìš”ì¼',4:'ê¸ˆìš”ì¼',5:'í† ìš”ì¼',6:'ì¼ìš”ì¼'}
    df['ìš”ì¼'] = df['DATE'].dt.dayofweek.map(wmap)
    df['ì£¼ì¤‘_or_ì£¼ë§'] = np.where(df['DATE'].dt.dayofweek >= 5, 'ì£¼ë§', 'ì£¼ì¤‘')
    df['CODE'] = df['ì§‘ê³„êµ¬ì½”ë“œ_str']
    
    def to_numeric_safe(col):
        return pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    male_total = sum(to_numeric_safe(col) for col in male_cols)
    female_total = sum(to_numeric_safe(col) for col in female_cols)
    
    return pd.DataFrame({
        'DATE': df['DATE'].dt.strftime('%Y-%m-%d'),
        'ìš”ì¼': df['ìš”ì¼'],
        'ì£¼ì¤‘_or_ì£¼ë§': df['ì£¼ì¤‘_or_ì£¼ë§'],
        'TIME': df['TIME'],
        'CODE': df['CODE'],
        'ë‚¨ì': male_total,
        'ì—¬ì': female_total,
        'ë‚¨ì 0-9': to_numeric_safe('ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ë‚¨ì 10-19': to_numeric_safe('ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ë‚¨ì 20-29': to_numeric_safe('ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ë‚¨ì 30-39': to_numeric_safe('ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ë‚¨ì 40-49': to_numeric_safe('ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ë‚¨ì 50-59': to_numeric_safe('ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ë‚¨ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ë‚¨ì 60-69': to_numeric_safe('ë‚¨ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ë‚¨ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ë‚¨ì 70+': to_numeric_safe('ë‚¨ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜'),
        'ì—¬ì 0-9': to_numeric_safe('ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ì—¬ì 10-19': to_numeric_safe('ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ì—¬ì 20-29': to_numeric_safe('ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ì—¬ì 30-39': to_numeric_safe('ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ì—¬ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ì—¬ì 40-49': to_numeric_safe('ì—¬ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ì—¬ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ì—¬ì 50-59': to_numeric_safe('ì—¬ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ì—¬ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ì—¬ì 60-69': to_numeric_safe('ì—¬ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜') + to_numeric_safe('ì—¬ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜'),
        'ì—¬ì 70+': to_numeric_safe('ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜')
    }).dropna(subset=['DATE','TIME','CODE'])

st.info("ğŸ“‹ í•„í„°ë§ ëŒ€ìƒ: CODE ì• 7ìë¦¬ê°€ 1104065, 1104066, 1104067, 1104068ì¸ ë°ì´í„°ë§Œ ì²˜ë¦¬")
st.info("ğŸ”„ íŒŒì¼ëª…ì— ë”°ë¼ ìë™ êµ¬ë¶„: TEMP_FOREIGNER â†’ ì™¸êµ­ì¸, LOCAL_PEOPLE â†’ êµ­ë‚´ì¸êµ¬")

uploaded = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type='csv', accept_multiple_files=True)

if uploaded:
    file_bytes = {f.name: f.read() for f in uploaded}
    
    # íŒŒì¼ ë¶„ë¥˜
    foreigner_files = [f for f in uploaded if 'TEMP_FOREIGNER' in f.name or 'FOREIGNER' in f.name]
    local_files = [f for f in uploaded if 'LOCAL_PEOPLE' in f.name]
    other_files = [f for f in uploaded if f not in foreigner_files + local_files]
    
    st.subheader("ì—…ë¡œë“œëœ íŒŒì¼ ë¶„ë¥˜")
    if foreigner_files:
        st.write(f"ğŸŒ ì™¸êµ­ì¸ íŒŒì¼: {len(foreigner_files)}ê°œ")
    if local_files:
        st.write(f"ğŸ  êµ­ë‚´ì¸êµ¬ íŒŒì¼: {len(local_files)}ê°œ")
    if other_files:
        st.write(f"â“ ê¸°íƒ€ íŒŒì¼: {len(other_files)}ê°œ")
    
    # ë¯¸ë¦¬ë³´ê¸°
    st.subheader("ì²« ë²ˆì§¸ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°")
    first_file = uploaded[0]
    sample = file_bytes[first_file.name]
    delim = detect_delimiter(sample)
    for enc in ('utf-8','cp949','utf-8-sig'):
        try:
            preview_df = pd.read_csv(io.BytesIO(sample), encoding=enc, delimiter=delim, nrows=5)
            preview_df.columns = preview_df.columns.str.strip().str.replace('"','').str.replace('?','')
            st.dataframe(preview_df)
            break
        except:
            continue

    st.markdown("---")

    if st.button("ì „ì²´ ì‹¤í–‰"):
        progress = st.progress(0)
        all_dfs, errors = [], []
        total_files = len(file_bytes)
        
        for i, (fname, content) in enumerate(file_bytes.items(), start=1):
            try:
                if 'LOCAL_PEOPLE' in fname:
                    df = process_local_file(content, fname)
                    file_type = "êµ­ë‚´ì¸êµ¬"
                else:
                    df = process_foreigner_file(content, fname)
                    file_type = "ì™¸êµ­ì¸"
                
                if len(df) > 0:
                    all_dfs.append(df)
                    st.write(f"âœ“ {fname} ({file_type}) ì²˜ë¦¬ ì™„ë£Œ: {len(df):,}í–‰")
                else:
                    st.write(f"â—‹ {fname} ({file_type}) ì²˜ë¦¬ ì™„ë£Œ: 0í–‰")
            except Exception as e:
                errors.append(f"{fname}: {e}")
                st.write(f"âœ— {fname} ì˜¤ë¥˜: {e}")
            progress.progress(i / total_files)

        if all_dfs:
            merged = pd.concat(all_dfs, ignore_index=True).drop_duplicates()
            merged['DATE'] = pd.Categorical(merged['DATE'])
            merged = merged.sort_values(['DATE','TIME','CODE']).reset_index(drop=True)
            st.success(f"âœ… í†µí•© ë³‘í•© ì™„ë£Œ: ì´ {len(merged):,}í–‰")
            
            bio = BytesIO()
            merged.to_excel(bio, index=False, engine='openpyxl')
            bio.seek(0)
            data_bytes = bio.getvalue()
            fn = f"integrated_merged_{datetime.now():%Y%m%d_%H%M%S}.xlsx"
            st.download_button("í†µí•© ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=data_bytes, file_name=fn,
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        else:
            st.warning("âš ï¸ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        if errors:
            st.error("ì˜¤ë¥˜ ë°œìƒ:")
            for e in errors:
                st.write("-", e)
