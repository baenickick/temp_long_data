import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from datetime import datetime
import io

st.set_page_config(page_title="ëŒ€ìš©ëŸ‰ ìƒí™œì¸êµ¬ ë°ì´í„° ë³‘í•©", layout="wide")
st.title("ëŒ€ìš©ëŸ‰ CSV ë³‘í•© (ì²­í¬ ì²˜ë¦¬)")

def detect_delimiter(sample_bytes):
    s = sample_bytes[:2048].decode('utf-8', errors='ignore')
    return '\t' if s.count('\t') > s.count(',') else ','

def process_file_chunks(content_bytes, filename, chunk_size=10000):
    """ì²­í¬ ë‹¨ìœ„ë¡œ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬"""
    delim = detect_delimiter(content_bytes)
    
    # ì¸ì½”ë”© ê°ì§€
    encoding = None
    for enc in ('utf-8', 'cp949', 'utf-8-sig'):
        try:
            pd.read_csv(io.BytesIO(content_bytes), encoding=enc, delimiter=delim, nrows=1)
            encoding = enc
            break
        except:
            continue
    
    if not encoding:
        raise ValueError(f"{filename}: ì¸ì½”ë”© ì‹¤íŒ¨")
    
    # í•„í„°ë§ ëŒ€ìƒ ì½”ë“œ
    target_codes = ['1104065', '1104066', '1104067', '1104068']
    processed_chunks = []
    
    # ì²­í¬ ë‹¨ìœ„ë¡œ íŒŒì¼ ì½ê¸°
    chunk_reader = pd.read_csv(
        io.BytesIO(content_bytes), 
        encoding=encoding, 
        delimiter=delim,
        chunksize=chunk_size,
        dtype=str,
        low_memory=False
    )
    
    chunk_count = 0
    for chunk in chunk_reader:
        chunk_count += 1
        
        # ì»¬ëŸ¼ ì •ë¦¬
        chunk.columns = chunk.columns.str.strip().str.replace('"','').str.replace('?','')
        
        # ì™¸êµ­ì¸ íŒŒì¼ ì²˜ë¦¬
        if 'FOREIGNER' in filename or 'TEMP_FOREIGNER' in filename:
            required = ['ê¸°ì¤€ì¼ID','ì‹œê°„ëŒ€êµ¬ë¶„','ì§‘ê³„êµ¬ì½”ë“œ','ì´ìƒí™œì¸êµ¬ìˆ˜','ì¤‘êµ­ì¸ì²´ë¥˜ì¸êµ¬ìˆ˜','ì¤‘êµ­ì™¸ì™¸êµ­ì¸ì²´ë¥˜ì¸êµ¬ìˆ˜']
            if all(c in chunk.columns for c in required):
                chunk_filtered = process_foreigner_chunk(chunk, required, target_codes)
                if len(chunk_filtered) > 0:
                    processed_chunks.append(chunk_filtered)
        
        # êµ­ë‚´ì¸êµ¬ íŒŒì¼ ì²˜ë¦¬
        elif 'LOCAL_PEOPLE' in filename:
            basic_cols = ['ê¸°ì¤€ì¼ID','ì‹œê°„ëŒ€êµ¬ë¶„','í–‰ì •ë™ì½”ë“œ','ì§‘ê³„êµ¬ì½”ë“œ','ì´ìƒí™œì¸êµ¬ìˆ˜']
            male_cols = [f'ë‚¨ì{age}ìƒí™œì¸êµ¬ìˆ˜' for age in ['0ì„¸ë¶€í„°9ì„¸','10ì„¸ë¶€í„°14ì„¸','15ì„¸ë¶€í„°19ì„¸','20ì„¸ë¶€í„°24ì„¸','25ì„¸ë¶€í„°29ì„¸','30ì„¸ë¶€í„°34ì„¸','35ì„¸ë¶€í„°39ì„¸','40ì„¸ë¶€í„°44ì„¸','45ì„¸ë¶€í„°49ì„¸','50ì„¸ë¶€í„°54ì„¸','55ì„¸ë¶€í„°59ì„¸','60ì„¸ë¶€í„°64ì„¸','65ì„¸ë¶€í„°69ì„¸','70ì„¸ì´ìƒ']]
            female_cols = [f'ì—¬ì{age}ìƒí™œì¸êµ¬ìˆ˜' for age in ['0ì„¸ë¶€í„°9ì„¸','10ì„¸ë¶€í„°14ì„¸','15ì„¸ë¶€í„°19ì„¸','20ì„¸ë¶€í„°24ì„¸','25ì„¸ë¶€í„°29ì„¸','30ì„¸ë¶€í„°34ì„¸','35ì„¸ë¶€í„°39ì„¸','40ì„¸ë¶€í„°44ì„¸','45ì„¸ë¶€í„°49ì„¸','50ì„¸ë¶€í„°54ì„¸','55ì„¸ë¶€í„°59ì„¸','60ì„¸ë¶€í„°64ì„¸','65ì„¸ë¶€í„°69ì„¸','70ì„¸ì´ìƒ']]
            
            if all(c in chunk.columns for c in basic_cols + male_cols + female_cols):
                chunk_filtered = process_local_chunk(chunk, basic_cols, male_cols, female_cols, target_codes)
                if len(chunk_filtered) > 0:
                    processed_chunks.append(chunk_filtered)
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if chunk_count % 10 == 0:
            st.write(f"  ğŸ“Š ì²­í¬ {chunk_count} ì²˜ë¦¬ ì¤‘...")
    
    return processed_chunks

def process_foreigner_chunk(chunk, required, target_codes):
    chunk = chunk[required].copy()
    chunk['ì§‘ê³„êµ¬ì½”ë“œ_str'] = chunk['ì§‘ê³„êµ¬ì½”ë“œ'].astype(str)
    filter_mask = chunk['ì§‘ê³„êµ¬ì½”ë“œ_str'].str[:7].isin(target_codes)
    chunk = chunk[filter_mask]
    
    if len(chunk) == 0:
        return pd.DataFrame()
    
    chunk['DATE'] = pd.to_datetime(chunk['ê¸°ì¤€ì¼ID'].astype(str), format='%Y%m%d', errors='coerce')
    chunk['TIME'] = pd.to_numeric(chunk['ì‹œê°„ëŒ€êµ¬ë¶„'], errors='coerce')
    wmap = {0:'ì›”ìš”ì¼',1:'í™”ìš”ì¼',2:'ìˆ˜ìš”ì¼',3:'ëª©ìš”ì¼',4:'ê¸ˆìš”ì¼',5:'í† ìš”ì¼',6:'ì¼ìš”ì¼'}
    chunk['ìš”ì¼'] = chunk['DATE'].dt.dayofweek.map(wmap)
    chunk['ì£¼ì¤‘_or_ì£¼ë§'] = np.where(chunk['DATE'].dt.dayofweek >= 5, 'ì£¼ë§', 'ì£¼ì¤‘')
    
    return pd.DataFrame({
        'DATE': chunk['DATE'].dt.strftime('%Y-%m-%d'),
        'ìš”ì¼': chunk['ìš”ì¼'],
        'ì£¼ì¤‘_or_ì£¼ë§': chunk['ì£¼ì¤‘_or_ì£¼ë§'],
        'TIME': chunk['TIME'],
        'CODE': chunk['ì§‘ê³„êµ¬ì½”ë“œ_str'],
        'ALL': pd.to_numeric(chunk['ì´ìƒí™œì¸êµ¬ìˆ˜'], errors='coerce'),
        'CHN': pd.to_numeric(chunk['ì¤‘êµ­ì¸ì²´ë¥˜ì¸êµ¬ìˆ˜'], errors='coerce'),
        'EXP_CHN': pd.to_numeric(chunk['ì¤‘êµ­ì™¸ì™¸êµ­ì¸ì²´ë¥˜ì¸êµ¬ìˆ˜'], errors='coerce')
    }).dropna(subset=['DATE','TIME','CODE'])

def process_local_chunk(chunk, basic_cols, male_cols, female_cols, target_codes):
    chunk = chunk[basic_cols + male_cols + female_cols].copy()
    chunk['ì§‘ê³„êµ¬ì½”ë“œ_str'] = chunk['ì§‘ê³„êµ¬ì½”ë“œ'].astype(str)
    filter_mask = chunk['ì§‘ê³„êµ¬ì½”ë“œ_str'].str[:7].isin(target_codes)
    chunk = chunk[filter_mask]
    
    if len(chunk) == 0:
        return pd.DataFrame()
    
    chunk['DATE'] = pd.to_datetime(chunk['ê¸°ì¤€ì¼ID'].astype(str), format='%Y%m%d', errors='coerce')
    chunk['TIME'] = pd.to_numeric(chunk['ì‹œê°„ëŒ€êµ¬ë¶„'], errors='coerce')
    wmap = {0:'ì›”ìš”ì¼',1:'í™”ìš”ì¼',2:'ìˆ˜ìš”ì¼',3:'ëª©ìš”ì¼',4:'ê¸ˆìš”ì¼',5:'í† ìš”ì¼',6:'ì¼ìš”ì¼'}
    chunk['ìš”ì¼'] = chunk['DATE'].dt.dayofweek.map(wmap)
    chunk['ì£¼ì¤‘_or_ì£¼ë§'] = np.where(chunk['DATE'].dt.dayofweek >= 5, 'ì£¼ë§', 'ì£¼ì¤‘')
    
    def to_numeric_safe(col):
        return pd.to_numeric(chunk[col], errors='coerce').fillna(0)
    
    male_total = sum(to_numeric_safe(col) for col in male_cols)
    female_total = sum(to_numeric_safe(col) for col in female_cols)
    
    return pd.DataFrame({
        'DATE': chunk['DATE'].dt.strftime('%Y-%m-%d'),
        'ìš”ì¼': chunk['ìš”ì¼'],
        'ì£¼ì¤‘_or_ì£¼ë§': chunk['ì£¼ì¤‘_or_ì£¼ë§'],
        'TIME': chunk['TIME'],
        'CODE': chunk['ì§‘ê³„êµ¬ì½”ë“œ_str'],
        'ë‚¨ì': male_total,
        'ì—¬ì': female_total
    }).dropna(subset=['DATE','TIME','CODE'])

st.warning("âš ï¸ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ìš© - íŒŒì¼ë‹¹ ìˆ˜ì‹­MB ì´ìƒë„ ì²˜ë¦¬ ê°€ëŠ¥")
st.info("ğŸ“‹ ì²­í¬ í¬ê¸°: 10,000í–‰ì”© ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”")

uploaded = st.file_uploader("ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ ì—…ë¡œë“œ", type='csv', accept_multiple_files=True)

if uploaded:
    st.subheader(f"ì—…ë¡œë“œëœ íŒŒì¼: {len(uploaded)}ê°œ")
    for f in uploaded:
        file_size_mb = len(f.read()) / (1024 * 1024)
        st.write(f"ğŸ“„ {f.name} ({file_size_mb:.1f}MB)")
    
    if st.button("ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œì‘"):
        file_bytes = {f.name: f.read() for f in uploaded}
        
        all_chunks = []
        total_files = len(file_bytes)
        progress = st.progress(0)
        
        for i, (fname, content) in enumerate(file_bytes.items(), start=1):
            st.write(f"ğŸ”„ {fname} ì²˜ë¦¬ ì¤‘...")
            try:
                chunks = process_file_chunks(content, fname)
                all_chunks.extend(chunks)
                st.write(f"âœ… {fname} ì™„ë£Œ - {len(chunks)}ê°œ ì²­í¬ ì²˜ë¦¬ë¨")
            except Exception as e:
                st.error(f"âŒ {fname} ì‹¤íŒ¨: {e}")
            progress.progress(i / total_files)
        
        if all_chunks:
            st.write("ğŸ”„ ìµœì¢… ë³‘í•© ì¤‘...")
            final_df = pd.concat(all_chunks, ignore_index=True).drop_duplicates()
            final_df = final_df.sort_values(['DATE','TIME','CODE']).reset_index(drop=True)
            
            st.success(f"ğŸ‰ ì™„ë£Œ! ì´ {len(final_df):,}í–‰ ì²˜ë¦¬ë¨")
            
            bio = BytesIO()
            final_df.to_excel(bio, index=False, engine='openpyxl')
            bio.seek(0)
            fn = f"large_merged_{datetime.now():%Y%m%d_%H%M%S}.xlsx"
            
            st.download_button(
                "ğŸ“¥ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=bio.getvalue(),
                file_name=fn,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
